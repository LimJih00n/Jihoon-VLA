# ğŸ­ Imitation Learning ìƒì„¸ ì„¤ëª…

## ğŸ“Œ ê°œìš”
Imitation Learning(ëª¨ë°© í•™ìŠµ)ì€ ì „ë¬¸ê°€ì˜ ì‹œì—°ì„ ê´€ì°°í•˜ê³  í•™ìŠµí•˜ì—¬ ìœ ì‚¬í•œ í–‰ë™ì„ ì¬í˜„í•˜ëŠ” í•™ìŠµ ë°©ë²•ì…ë‹ˆë‹¤. ê°•í™”í•™ìŠµê³¼ ë‹¬ë¦¬ ë³´ìƒ í•¨ìˆ˜ ì„¤ê³„ê°€ ë¶ˆí•„ìš”í•˜ë©°, ì¸ê°„ì˜ ì‹œì—° ë°ì´í„°ë¥¼ ì§ì ‘ í™œìš©í•  ìˆ˜ ìˆì–´ ë¡œë´‡ í•™ìŠµì— ë§¤ìš° íš¨ê³¼ì ì…ë‹ˆë‹¤.

## ğŸ¯ í•µì‹¬ ê°œë…

### 1. ëª¨ë°© í•™ìŠµì˜ ê¸°ë³¸ ì›ë¦¬

#### í•™ìŠµ íŒ¨ëŸ¬ë‹¤ì„ ë¹„êµ
| ë°©ë²• | ë°ì´í„° | ì¥ì  | ë‹¨ì  |
|------|--------|------|------|
| **ì§€ë„ í•™ìŠµ** | (ì…ë ¥, ì •ë‹µ) | ê°„ë‹¨, ë¹ ë¦„ | ì •ë‹µ ë¼ë²¨ í•„ìš” |
| **ê°•í™” í•™ìŠµ** | (ìƒíƒœ, í–‰ë™, ë³´ìƒ) | ììœ¨ í•™ìŠµ | ë³´ìƒ ì„¤ê³„ ì–´ë ¤ì›€, ëŠë¦¼ |
| **ëª¨ë°© í•™ìŠµ** | (ìƒíƒœ, ì „ë¬¸ê°€ í–‰ë™) | ë³´ìƒ ë¶ˆí•„ìš”, ë¹ ë¦„ | ì „ë¬¸ê°€ ì‹œì—° í•„ìš” |

#### ëª¨ë°© í•™ìŠµì˜ ëª©í‘œ
```
Given: ì „ë¬¸ê°€ ì‹œì—° D = {(sâ‚, aâ‚), (sâ‚‚, aâ‚‚), ..., (sâ‚™, aâ‚™)}
Goal: Ï€(a|s) â‰ˆ Ï€_expert(a|s)
```

### 2. ì£¼ìš” ì ‘ê·¼ ë°©ë²•

#### Behavioral Cloning (BC)
**ì›ë¦¬**: ì§€ë„ í•™ìŠµìœ¼ë¡œ ì „ë¬¸ê°€ í–‰ë™ ì§ì ‘ ë³µì œ
```
min_Î¸ E[(Ï€_Î¸(s) - a_expert)Â²]
```

**ì¥ì :**
- êµ¬í˜„ì´ ê°„ë‹¨
- í•™ìŠµì´ ë¹ ë¦„
- ì•ˆì •ì ì¸ ìˆ˜ë ´

**ë‹¨ì :**
- Distribution shift ë¬¸ì œ
- Compounding errors
- ì „ë¬¸ê°€ ë°ì´í„°ì— ê³¼ì í•©

#### Dataset Aggregation (DAgger)
**ì›ë¦¬**: ë°˜ë³µì ìœ¼ë¡œ ë°ì´í„° ìˆ˜ì§‘í•˜ë©° distribution shift í•´ê²°
```
1. ì´ˆê¸° ì •ì±… Ï€â‚€ë¥¼ ì „ë¬¸ê°€ ë°ì´í„°ë¡œ í•™ìŠµ
2. Ï€_ië¥¼ ì‹¤í–‰í•˜ë©° ìƒˆë¡œìš´ ìƒíƒœ ìˆ˜ì§‘
3. ìƒˆë¡œìš´ ìƒíƒœì— ëŒ€í•œ ì „ë¬¸ê°€ ë¼ë²¨ íšë“
4. ë°ì´í„° ì§‘ê³„ í›„ ì¬í•™ìŠµ
```

**ê°œì„ ì :**
- Covariate shift ì™„í™”
- ë” ê°•ê±´í•œ ì •ì±… í•™ìŠµ
- ì˜¨ë¼ì¸ ì ì‘ ê°€ëŠ¥

#### Inverse Reinforcement Learning (IRL)
**ì›ë¦¬**: ì „ë¬¸ê°€ ì‹œì—°ìœ¼ë¡œë¶€í„° ë³´ìƒ í•¨ìˆ˜ ì¶”ë¡ 
```
Given: ì „ë¬¸ê°€ ê¶¤ì  Ï„_expert
Find: R(s,a) such that Ï„_expert = argmax E[Î£ R(s,a)]
```

**íŠ¹ì§•:**
- ë³´ìƒ í•¨ìˆ˜ í•™ìŠµ
- ì „ì´ ê°€ëŠ¥í•œ ì§€ì‹
- ê³„ì‚° ë³µì¡ë„ ë†’ìŒ

#### Generative Adversarial Imitation Learning (GAIL)
**ì›ë¦¬**: GAN êµ¬ì¡°ë¡œ ì „ë¬¸ê°€ ë¶„í¬ ë§¤ì¹­
```
Discriminator: ì „ë¬¸ê°€ vs ì •ì±… êµ¬ë¶„
Generator: ì „ë¬¸ê°€ì²˜ëŸ¼ ë³´ì´ëŠ” í–‰ë™ ìƒì„±
```

**ì¥ì :**
- ë³´ìƒ í•¨ìˆ˜ ë¶ˆí•„ìš”
- ë¶„í¬ ìˆ˜ì¤€ ë§¤ì¹­
- ë†’ì€ ì„±ëŠ¥

## ğŸ—ï¸ í•µì‹¬ ì•Œê³ ë¦¬ì¦˜ ìƒì„¸

### 1. Behavioral Cloning ì‹¬í™”

#### ë¬¸ì œì : Covariate Shift
```
Training: p_train(s) = p_expert(s)
Testing: p_test(s) = p_Ï€(s) â‰  p_expert(s)
```

ì‹œê°„ì´ ì§€ë‚ ìˆ˜ë¡ ìƒíƒœ ë¶„í¬ê°€ ë‹¬ë¼ì ¸ ì„±ëŠ¥ ì €í•˜

#### í•´ê²° ë°©ë²•
1. **Data Augmentation**
   - ë…¸ì´ì¦ˆ ì¶”ê°€
   - ìƒíƒœ ë³€í™˜
   - Trajectory perturbation

2. **Ensemble Methods**
   - Multiple policies
   - Uncertainty estimation
   - Robust aggregation

3. **Regularization**
   - Dropout
   - Weight decay
   - Early stopping

### 2. DAgger ì•Œê³ ë¦¬ì¦˜ ìƒì„¸

#### ì•Œê³ ë¦¬ì¦˜ ê³¼ì •
```python
Initialize: D â† âˆ…, Ï€â‚€ â† random
for i = 0 to N:
    # í˜„ì¬ ì •ì±…ìœ¼ë¡œ ê¶¤ì  ìˆ˜ì§‘
    Ï„áµ¢ = rollout(Ï€áµ¢)
    
    # ì „ë¬¸ê°€ ë¼ë²¨ íšë“
    for (s,a) in Ï„áµ¢:
        a* = expert(s)
        D â† D âˆª {(s, a*)}
    
    # ì§‘ê³„ëœ ë°ì´í„°ë¡œ í•™ìŠµ
    Ï€áµ¢â‚Šâ‚ = train(D)
```

#### Î²-DAgger (Mixture Policy)
```
Ï€_mix = Î²Ï€_expert + (1-Î²)Ï€_learned
Î² = Î²â‚€ * decay^i
```
ì ì§„ì ìœ¼ë¡œ ì „ë¬¸ê°€ ì˜ì¡´ë„ ê°ì†Œ

### 3. Maximum Entropy IRL

#### ì›ë¦¬
```
P(Ï„) âˆ exp(R(Ï„))
```
ë³´ìƒì´ ë†’ì€ ê¶¤ì ì¼ìˆ˜ë¡ í™•ë¥  ë†’ìŒ

#### íŠ¹ì§• ë§¤ì¹­
```
E_Ï€[f(s,a)] = E_expert[f(s,a)]
```
ì „ë¬¸ê°€ì™€ í•™ìŠµ ì •ì±…ì˜ íŠ¹ì§• ê¸°ëŒ“ê°’ ë§¤ì¹­

#### Gradient
```
âˆ‡R = E_expert[f] - E_Ï€[f]
```

### 4. GAIL êµ¬ì¡° ìƒì„¸

#### Discriminator Objective
```
max_D E_expert[log D(s,a)] + E_Ï€[log(1-D(s,a))]
```

#### Generator Objective
```
max_Ï€ E_Ï€[log D(s,a)] = min_Ï€ E_Ï€[-log D(s,a)]
```

#### ì‹¤ì œ êµ¬í˜„ íŠ¸ë¦­
1. **Gradient Penalty**: Lipschitz ì œì•½
2. **Spectral Normalization**: ì•ˆì •ì„±
3. **Experience Replay**: ìƒ˜í”Œ íš¨ìœ¨ì„±

## ğŸ¤– ë¡œë´‡ ì‹œì—° ë°ì´í„° ìˆ˜ì§‘

### 1. í…”ë ˆì˜¤í¼ë ˆì´ì…˜ (Teleoperation)

#### ë°©ë²•
- **ì¡°ì´ìŠ¤í‹±/ê²Œì„íŒ¨ë“œ**: ì§ê´€ì  ì œì–´
- **ë§ˆìŠ¤í„°-ìŠ¬ë ˆì´ë¸Œ**: ë™ì¼ êµ¬ì¡° ë¡œë´‡
- **VR ì»¨íŠ¸ë¡¤ëŸ¬**: 6-DOF ì œì–´
- **í–…í‹± ë””ë°”ì´ìŠ¤**: í˜ í”¼ë“œë°±

#### ì¥ì ê³¼ ë‹¨ì 
| ì¥ì  | ë‹¨ì  |
|------|------|
| ì§ê´€ì  ì œì–´ | í”¼ë¡œë„ ë†’ìŒ |
| ì‹¤ì‹œê°„ í”¼ë“œë°± | ì •ë°€ë„ ì œí•œ |
| ì•ˆì „í•œ ë°ì´í„° ìˆ˜ì§‘ | íŠ¹ìˆ˜ ì¥ë¹„ í•„ìš” |

### 2. í‚¤ë„¤ìŠ¤í…Œí‹± í‹°ì¹­ (Kinesthetic Teaching)

#### ê³¼ì •
1. ë¡œë´‡ì„ ì¤‘ë ¥ ë³´ìƒ ëª¨ë“œë¡œ ì„¤ì •
2. ë¬¼ë¦¬ì ìœ¼ë¡œ ë¡œë´‡ íŒ” ì´ë™
3. ê¶¤ì  ê¸°ë¡
4. í›„ì²˜ë¦¬ ë° ìŠ¤ë¬´ë”©

#### ë°ì´í„° í’ˆì§ˆ í–¥ìƒ
```python
def smooth_trajectory(trajectory, window_size=5):
    """Gaussian smoothing for kinesthetic demonstrations"""
    smoothed = []
    for i in range(len(trajectory)):
        start = max(0, i - window_size//2)
        end = min(len(trajectory), i + window_size//2 + 1)
        smoothed.append(np.mean(trajectory[start:end], axis=0))
    return np.array(smoothed)
```

### 3. ë¹„ì£¼ì–¼ ì‹œì—° (Visual Demonstrations)

#### ì²˜ë¦¬ ê³¼ì •
1. **ë¹„ë””ì˜¤ ìˆ˜ì§‘**: ì¸ê°„ ì‘ì—… ë…¹í™”
2. **í¬ì¦ˆ ì¶”ì •**: ê´€ì ˆ ìœ„ì¹˜ ì¶”ì¶œ
3. **ë¦¬íƒ€ê²ŒíŒ…**: ë¡œë´‡ êµ¬ì¡°ë¡œ ë§¤í•‘
4. **ê¶¤ì  ìµœì í™”**: ì‹¤í–‰ ê°€ëŠ¥í•œ ê¶¤ì  ìƒì„±

#### ë„ì „ ê³¼ì œ
- ê´€ì  ì°¨ì´ (3ì¸ì¹­ â†’ 1ì¸ì¹­)
- ìŠ¤ì¼€ì¼ ì°¨ì´ (ì¸ê°„ â†’ ë¡œë´‡)
- ì†ë„ ì°¨ì´ (ì‹¤ì‹œê°„ â†’ ë¡œë´‡ ì†ë„)

## ğŸ”¬ ê³ ê¸‰ ê¸°ë²•

### 1. One-Shot Imitation Learning

#### ëª©í‘œ
ë‹¨ì¼ ì‹œì—°ìœ¼ë¡œ ìƒˆë¡œìš´ ì‘ì—… í•™ìŠµ

#### ì ‘ê·¼ ë°©ë²•
1. **Meta-Learning**: ë¹ ë¥¸ ì ì‘ í•™ìŠµ
2. **Modular Networks**: ì¬ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë“ˆ
3. **Program Synthesis**: ì‘ì—… ë¶„í•´

#### êµ¬í˜„ ì˜ˆì‹œ
```python
class OneShotImitation:
    def __init__(self):
        self.encoder = TaskEncoder()
        self.policy = ConditionalPolicy()
    
    def learn_from_demo(self, demo):
        # ì‹œì—°ì„ ì‘ì—… ì„ë² ë”©ìœ¼ë¡œ ì¸ì½”ë”©
        task_embedding = self.encoder(demo)
        
        # ì¡°ê±´ë¶€ ì •ì±… ìƒì„±
        return lambda s: self.policy(s, task_embedding)
```

### 2. Hierarchical Imitation Learning

#### ê³„ì¸µ êµ¬ì¡°
```
High-level: ì‘ì—… ê³„íš (pick â†’ move â†’ place)
Mid-level: ìŠ¤í‚¬ ì„ íƒ (grasp, transport, release)
Low-level: ëª¨í„° ì œì–´ (joint torques)
```

#### ì¥ì 
- ë³µì¡í•œ ì‘ì—… ë¶„í•´
- ìŠ¤í‚¬ ì¬ì‚¬ìš©
- í•´ì„ ê°€ëŠ¥ì„±

### 3. Multi-Modal Imitation

#### ëª¨ë‹¬ë¦¬í‹° í†µí•©
```python
class MultiModalImitation:
    def __init__(self):
        self.vision_encoder = VisionEncoder()
        self.language_encoder = LanguageEncoder()
        self.force_encoder = ForceEncoder()
        self.fusion = CrossModalAttention()
    
    def process(self, vision, language, force):
        v_feat = self.vision_encoder(vision)
        l_feat = self.language_encoder(language)
        f_feat = self.force_encoder(force)
        
        # Cross-modal fusion
        fused = self.fusion(v_feat, l_feat, f_feat)
        return self.policy(fused)
```

## ğŸ’¡ ì‹¤ì „ ì ìš© ê°€ì´ë“œ

### 1. ë°ì´í„° ìˆ˜ì§‘ ì „ëµ

#### í’ˆì§ˆ vs ìˆ˜ëŸ‰
- **ê³ í’ˆì§ˆ ì†ŒëŸ‰**: BCì— ì í•©
- **ì¤‘í’ˆì§ˆ ëŒ€ëŸ‰**: DAgger, GAILì— ì í•©
- **ë‹¤ì–‘ì„± ì¤‘ìš”**: ë‹¤ì–‘í•œ ì‹œë‚˜ë¦¬ì˜¤ í¬í•¨

#### ë°ì´í„° í•„í„°ë§
```python
def filter_demonstrations(demos, threshold=0.8):
    """Filter out low-quality demonstrations"""
    filtered = []
    for demo in demos:
        if demo['success_rate'] > threshold:
            if check_safety_constraints(demo):
                if not has_redundant_actions(demo):
                    filtered.append(demo)
    return filtered
```

### 2. ì•Œê³ ë¦¬ì¦˜ ì„ íƒ ê¸°ì¤€

| ìƒí™© | ì¶”ì²œ ì•Œê³ ë¦¬ì¦˜ | ì´ìœ  |
|------|--------------|------|
| ì ì€ ë°ì´í„° | BC + ì¦ê°• | ë‹¨ìˆœí•˜ê³  ë¹ ë¦„ |
| ì˜¨ë¼ì¸ í•™ìŠµ ê°€ëŠ¥ | DAgger | Distribution shift í•´ê²° |
| ë³´ìƒ í•¨ìˆ˜ í•„ìš” | IRL | ì „ì´ ê°€ëŠ¥í•œ ì§€ì‹ |
| ëŒ€ëŸ‰ ë°ì´í„° | GAIL | ë†’ì€ ì„±ëŠ¥ |

### 3. ì„±ëŠ¥ í–¥ìƒ ê¸°ë²•

#### ì•™ìƒë¸” ë°©ë²•
```python
class EnsembleImitation:
    def __init__(self, n_models=5):
        self.models = [BCModel() for _ in range(n_models)]
    
    def predict(self, state):
        predictions = [m(state) for m in self.models]
        # Uncertainty-weighted averaging
        weights = [1/m.uncertainty(state) for m in self.models]
        return weighted_average(predictions, weights)
```

#### Curriculum Learning
1. ì‰¬ìš´ ì‘ì—…ë¶€í„° ì‹œì‘
2. ì ì§„ì ìœ¼ë¡œ ë‚œì´ë„ ì¦ê°€
3. ì‹¤íŒ¨ ì‹œ ì´ì „ ë‹¨ê³„ ë³µìŠµ

## ğŸš€ ìµœì‹  ì—°êµ¬ ë™í–¥

### 1. Diffusion Models for IL
- í™•ì‚° ëª¨ë¸ë¡œ ë‹¤ì–‘í•œ í–‰ë™ ìƒì„±
- ë‹¤ì¤‘ ëª¨ë“œ í–‰ë™ ëª¨ë¸ë§
- ë¶ˆí™•ì‹¤ì„± ì •ëŸ‰í™”

### 2. Transformer-based IL
- ê¸´ ì‹œí€€ìŠ¤ ëª¨ë¸ë§
- Attentionìœ¼ë¡œ ì¤‘ìš” í”„ë ˆì„ í¬ì°©
- In-context learning

### 3. Self-Supervised IL
- ë¼ë²¨ ì—†ëŠ” ë°ì´í„° í™œìš©
- Contrastive learning
- í‘œí˜„ í•™ìŠµ ê°•í™”

## âš ï¸ ì£¼ì˜ì‚¬í•­ ë° í•œê³„

### ì£¼ìš” ë¬¸ì œì 
1. **Causal Confusion**: ìƒê´€ê´€ê³„ë¥¼ ì¸ê³¼ê´€ê³„ë¡œ ì˜¤í•´
2. **Negative Transfer**: ì˜ëª»ëœ ì¼ë°˜í™”
3. **Expert Suboptimality**: ë¶ˆì™„ì „í•œ ì „ë¬¸ê°€
4. **Domain Gap**: ì‹œë®¬ë ˆì´ì…˜ê³¼ ì‹¤ì œ ì°¨ì´

### í•´ê²° ë°©ì•ˆ
1. **Causal Inference**: ì¸ê³¼ ê´€ê³„ ëª…ì‹œì  ëª¨ë¸ë§
2. **Domain Randomization**: ë‹¤ì–‘í•œ í™˜ê²½ í•™ìŠµ
3. **Expert Mixture**: ì—¬ëŸ¬ ì „ë¬¸ê°€ í™œìš©
4. **Active Learning**: ë¶ˆí™•ì‹¤í•œ ë¶€ë¶„ ì§ˆì˜

## ğŸ“š ì¶”ê°€ í•™ìŠµ ìë£Œ

### í•µì‹¬ ë…¼ë¬¸
- "A Reduction of Imitation Learning and Structured Prediction to No-Regret Online Learning" (DAgger)
- "Maximum Entropy Inverse Reinforcement Learning" (MaxEnt IRL)
- "Generative Adversarial Imitation Learning" (GAIL)

### ë„êµ¬ ë° í”„ë ˆì„ì›Œí¬
- imitation (Python library)
- RoboSuite (ì‹œë®¬ë ˆì´í„°)
- DART (ë°ì´í„°ì…‹)

### ë²¤ì¹˜ë§ˆí¬
- RoboMimic
- D4RL
- RLBench

## ğŸ¯ í•µì‹¬ ìš”ì•½

ëª¨ë°© í•™ìŠµì€ ì „ë¬¸ê°€ ì‹œì—°ì„ í†µí•´ ë¹ ë¥´ê²Œ í•™ìŠµí•  ìˆ˜ ìˆëŠ” ê°•ë ¥í•œ ë°©ë²•ì…ë‹ˆë‹¤. BCì˜ ë‹¨ìˆœí•¨ë¶€í„° GAILì˜ ì •êµí•¨ê¹Œì§€ ë‹¤ì–‘í•œ ì ‘ê·¼ì´ ê°€ëŠ¥í•˜ë©°, ê° ë°©ë²•ì˜ ì¥ë‹¨ì ì„ ì´í•´í•˜ê³  ì ì ˆíˆ ì„ íƒí•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤. Distribution shift ë¬¸ì œ í•´ê²°, ë°ì´í„° í’ˆì§ˆ í™•ë³´, ì•ˆì „ì„± ë³´ì¥ì´ ì„±ê³µì ì¸ êµ¬í˜„ì˜ í•µì‹¬ì…ë‹ˆë‹¤.