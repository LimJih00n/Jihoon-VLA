# ğŸ“š Ï€0 (Pi-Zero) ì™„ë²½ í•™ìŠµ ê°€ì´ë“œ
## Physical Intelligenceì˜ í˜ì‹ ì  Flow Matching VLA ëª¨ë¸

---

## ğŸ“Œ Table of Contents
1. [ì‚¬ì „ ì§€ì‹ ìš”êµ¬ì‚¬í•­](#1-ì‚¬ì „-ì§€ì‹-ìš”êµ¬ì‚¬í•­)
2. [Flow Matching ì´ë¡ ì  ë°°ê²½](#2-flow-matching-ì´ë¡ ì -ë°°ê²½)
3. [Ï€0 ëª¨ë¸ ìƒì„¸ ë¶„ì„](#3-Ï€0-ëª¨ë¸-ìƒì„¸-ë¶„ì„)
4. [ê´€ë ¨ ë…¼ë¬¸ íƒ€ì„ë¼ì¸](#4-ê´€ë ¨-ë…¼ë¬¸-íƒ€ì„ë¼ì¸)
5. [êµ¬í˜„ ì„¸ë¶€ì‚¬í•­](#5-êµ¬í˜„-ì„¸ë¶€ì‚¬í•­)
6. [ì‹¤ìŠµ ê°€ì´ë“œ](#6-ì‹¤ìŠµ-ê°€ì´ë“œ)

---

## 1. ì‚¬ì „ ì§€ì‹ ìš”êµ¬ì‚¬í•­

### 1.1 í•„ìˆ˜ ê°œë…
```python
prerequisites = {
    "ìˆ˜í•™ì  ê¸°ì´ˆ": [
        "í™•ë¥ ë¡  (Probability Theory)",
        "ìµœì  ìˆ˜ì†¡ ì´ë¡  (Optimal Transport)",
        "í™•ë¥ ë¯¸ë¶„ë°©ì •ì‹ (SDE)",
        "ë³€ë¶„ ì¶”ë¡  (Variational Inference)"
    ],
    
    "ML/DL ê¸°ì´ˆ": [
        "Diffusion Models",
        "Normalizing Flows", 
        "Score Matching",
        "Energy-Based Models"
    ],
    
    "ë¡œë³´í‹±ìŠ¤": [
        "Action Spaces (continuous/discrete)",
        "Trajectory Optimization",
        "Imitation Learning",
        "Behavior Cloning"
    ]
}
```

### 1.2 ì„ ìˆ˜ ë…¼ë¬¸ í•„ë… ë¦¬ìŠ¤íŠ¸
```markdown
## Diffusion ê³„ì—´ (ê¸°ì´ˆ)
1. **DDPM** (2020): "Denoising Diffusion Probabilistic Models"
   - Diffusionì˜ ê¸°ì´ˆ ì´í•´ í•„ìˆ˜
   
2. **Score-Based Models** (2021): "Score-Based Generative Modeling"
   - Score matching ê°œë…

3. **Diffusion Policy** (2023): "Diffusion Policy: Visuomotor Policy Learning"
   - ë¡œë³´í‹±ìŠ¤ì— Diffusion ì ìš©

## Flow ê³„ì—´ (í•µì‹¬)
4. **Normalizing Flows** (2019): "Normalizing Flows for Probabilistic Modeling"
   - Flow ê¸°ë°˜ ìƒì„± ëª¨ë¸ ê¸°ì´ˆ

5. **Flow Matching** (2023): "Flow Matching for Generative Modeling"
   - Ï€0ì˜ ì´ë¡ ì  í† ëŒ€ â­

6. **Rectified Flow** (2023): "Flow Straight and Fast"
   - Linear interpolationì˜ íš¨ìœ¨ì„±
```

---

## 2. Flow Matching ì´ë¡ ì  ë°°ê²½

### 2.1 í•µì‹¬ ìˆ˜í•™ì  ì›ë¦¬

#### **Diffusion vs Flow Matching**
```python
# Diffusion: í™•ë¥ ì  ê³¼ì • (Stochastic)
def diffusion_process(x_0, t):
    """
    Forward process: x_0 â†’ x_t (ë…¸ì´ì¦ˆ ì¶”ê°€)
    dx_t = -0.5 * Î²(t) * x_t dt + sqrt(Î²(t)) dW_t
    """
    noise = torch.randn_like(x_0)
    alpha_t = compute_alpha(t)
    x_t = sqrt(alpha_t) * x_0 + sqrt(1 - alpha_t) * noise
    return x_t

# Flow Matching: ê²°ì •ì  ê³¼ì • (Deterministic)  
def flow_matching(x_0, x_1, t):
    """
    Transport: x_0 â†’ x_1 (ì§ì ‘ ì´ë™)
    x_t = (1-t) * x_0 + t * x_1
    """
    return (1 - t) * x_0 + t * x_1
```

#### **ì™œ Flow Matchingì´ ë¹ ë¥¸ê°€?**
```python
# 1. Straight Path (ì§ì„  ê²½ë¡œ)
"""
Diffusion: ê³¡ì„  ê²½ë¡œë¡œ ëŒì•„ê°
Flow: ì§ì„  ê²½ë¡œë¡œ ì§ì§„
â†’ ë” ì ì€ stepìœ¼ë¡œ ë„ë‹¬
"""

# 2. Optimal Transport
"""
ìµœì  ìˆ˜ì†¡ ì´ë¡ ì— ê¸°ë°˜
Wasserstein distance ìµœì†Œí™”
â†’ ê°€ì¥ íš¨ìœ¨ì ì¸ ê²½ë¡œ
"""

# 3. Simulation-Free Training
"""
Diffusion: ì „ì²´ trajectory ì‹œë®¬ë ˆì´ì…˜ í•„ìš”
Flow: ì„ì˜ì˜ tì—ì„œ ì§ì ‘ í•™ìŠµ ê°€ëŠ¥
â†’ í›ˆë ¨ 5-10ë°° ë¹ ë¦„
"""
```

### 2.2 Flow Matching ì•Œê³ ë¦¬ì¦˜

```python
class FlowMatching:
    """Flow Matching í•µì‹¬ ì•Œê³ ë¦¬ì¦˜"""
    
    def __init__(self):
        self.velocity_net = VelocityNetwork()  # v_Î¸(x_t, t)
    
    def training_step(self, x_0, x_1):
        """í›ˆë ¨: velocity field í•™ìŠµ"""
        # 1. ëœë¤ ì‹œê°„ ìƒ˜í”Œë§
        t = torch.rand(batch_size, 1)
        
        # 2. Interpolation
        x_t = (1 - t) * x_0 + t * x_1
        
        # 3. Target velocity (ground truth)
        v_target = x_1 - x_0  # ì§ì„  ì†ë„
        
        # 4. Predicted velocity
        v_pred = self.velocity_net(x_t, t)
        
        # 5. Loss
        loss = MSE(v_pred, v_target)
        return loss
    
    def generate(self, x_0, steps=5):
        """ìƒì„±: ODE í’€ê¸°"""
        x = x_0
        dt = 1.0 / steps
        
        for i in range(steps):
            t = i * dt
            v = self.velocity_net(x, t)
            x = x + v * dt  # Euler integration
            
        return x  # x_1 (ìµœì¢… ì¶œë ¥)
```

---

## 3. Ï€0 ëª¨ë¸ ìƒì„¸ ë¶„ì„

### 3.1 ì•„í‚¤í…ì²˜ êµ¬ì¡°

```python
class Pi0Architecture:
    """Ï€0 ì „ì²´ ì•„í‚¤í…ì²˜"""
    
    def __init__(self):
        # Vision Encoder
        self.vision_encoder = PaliGemma3B(
            image_size=224,
            patch_size=14,
            hidden_dim=1024
        )
        
        # Language Processor  
        self.language_processor = Gemma2B(
            vocab_size=256128,
            hidden_dim=2048
        )
        
        # Cross-Modal Fusion
        self.fusion = CrossAttention(
            vision_dim=1024,
            language_dim=2048,
            output_dim=1536
        )
        
        # Flow Matching Policy Head
        self.flow_policy = FlowMatchingHead(
            input_dim=1536,
            action_dim=7,  # 7-DoF robot
            hidden_dim=1024,
            num_layers=6
        )
    
    def forward(self, image, text, t=None):
        # 1. Encode inputs
        vision_features = self.vision_encoder(image)
        language_features = self.language_processor(text)
        
        # 2. Fusion
        fused = self.fusion(vision_features, language_features)
        
        # 3. Generate action via Flow
        if self.training:
            # Training: predict velocity
            velocity = self.flow_policy.predict_velocity(fused, t)
            return velocity
        else:
            # Inference: generate action
            action = self.flow_policy.generate(fused, steps=5)
            return action
```

### 3.2 í›ˆë ¨ ë°ì´í„° ë° ê³¼ì •

```python
training_details = {
    "ë°ì´í„°ì…‹": {
        "ê·œëª¨": "10,000ì‹œê°„ ë¡œë´‡ ë°ëª¨",
        "ë‹¤ì–‘ì„±": "7ì¢… ë¡œë´‡, 100+ íƒœìŠ¤í¬",
        "ìˆ˜ì§‘": "ì›ê²©ì¡°ì‘ + ììœ¨ìˆ˜ì§‘"
    },
    
    "í›ˆë ¨ ê³¼ì •": {
        "Phase 1": "Behavior Cloning (100K steps)",
        "Phase 2": "Flow Matching (500K steps)",
        "Phase 3": "Online Fine-tuning (100K steps)"
    },
    
    "í•˜ì´í¼íŒŒë¼ë¯¸í„°": {
        "learning_rate": 1e-4,
        "batch_size": 256,
        "flow_steps_train": 100,
        "flow_steps_inference": 5,
        "optimizer": "AdamW"
    }
}
```

### 3.3 í•µì‹¬ í˜ì‹  í¬ì¸íŠ¸

```python
innovations = {
    "1. Continuous Action Generation": """
        - ì´ì‚° í† í° ëŒ€ì‹  ì—°ì† trajectory
        - ë¶€ë“œëŸ¬ìš´ ì›€ì§ì„ ìƒì„±
        - 50Hz ê³ ì£¼íŒŒ ì œì–´
    """,
    
    "2. Pre-training Strategy": """
        - Vision: PaliGemma (ì‚¬ì „í›ˆë ¨)
        - Language: Gemma-2B (ì‚¬ì „í›ˆë ¨)
        - Policy: Flow Matching (ì²˜ìŒë¶€í„°)
    """,
    
    "3. Multi-Resolution Control": """
        - Coarse: ì „ì²´ trajectory ê³„íš
        - Fine: 50Hz ì„¸ë°€ ì œì–´
        - Adaptive: ìƒí™©ë³„ ì£¼íŒŒìˆ˜ ì¡°ì •
    """
}
```

---

## 4. ê´€ë ¨ ë…¼ë¬¸ íƒ€ì„ë¼ì¸

### 4.1 Evolution Path

```mermaid
graph TD
    A[2020: DDPM] --> B[2021: Score-Based]
    B --> C[2022: Diffusion Policy]
    C --> D[2023: Flow Matching]
    D --> E[2024.11: Ï€0]
    
    F[2022: RT-1] --> G[2023: RT-2]
    G --> H[2024: OpenVLA]
    H --> E
    
    style E fill:#f9f,stroke:#333,stroke-width:4px
```

### 4.2 ì£¼ìš” ë…¼ë¬¸ ìƒì„¸

```markdown
## 2023ë…„
- **Flow Matching for Generative Modeling** (Lipman et al.)
  - Flow Matching ì´ë¡  ì •ë¦½
  - Citation: 500+

- **Diffusion Policy** (Chi et al., Columbia)
  - ë¡œë´‡ ì œì–´ì— Diffusion ì ìš©
  - Citation: 300+

## 2024ë…„
- **OpenVLA** (Kim et al., Stanford)
  - ì˜¤í”ˆì†ŒìŠ¤ VLA ê¸°ì¤€ì 
  - Citation: 200+

- **3D Diffusion Policy** (Ze et al.)
  - 3D ì¸ì‹ ì¶”ê°€
  - Citation: 100+

- **Ï€0** (Physical Intelligence)
  - Flow Matching + VLA
  - ìµœì‹ , Citation ê¸‰ì¦ ì¤‘
```

---

## 5. êµ¬í˜„ ì„¸ë¶€ì‚¬í•­

### 5.1 Flow Matching êµ¬í˜„ (PyTorch)

```python
import torch
import torch.nn as nn
import torch.nn.functional as F

class FlowMatchingPolicy(nn.Module):
    """Ï€0 ìŠ¤íƒ€ì¼ Flow Matching Policy"""
    
    def __init__(self, state_dim, action_dim, hidden_dim=256):
        super().__init__()
        
        # Velocity Network v_Î¸(x_t, t)
        self.velocity_net = nn.Sequential(
            nn.Linear(state_dim + action_dim + 1, hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, action_dim)
        )
        
    def compute_velocity(self, state, action_t, t):
        """Velocity prediction v_Î¸(x_t, t)"""
        # Concatenate inputs
        inputs = torch.cat([state, action_t, t], dim=-1)
        return self.velocity_net(inputs)
    
    def training_loss(self, state, action_0, action_1):
        """Flow Matching training loss"""
        batch_size = state.shape[0]
        
        # Sample random time
        t = torch.rand(batch_size, 1).to(state.device)
        
        # Interpolate
        action_t = (1 - t) * action_0 + t * action_1
        
        # True velocity
        v_true = action_1 - action_0
        
        # Predicted velocity
        v_pred = self.compute_velocity(state, action_t, t)
        
        # MSE loss
        loss = F.mse_loss(v_pred, v_true)
        return loss
    
    def generate(self, state, action_0, num_steps=5):
        """Generate action via ODE integration"""
        dt = 1.0 / num_steps
        action = action_0
        
        for i in range(num_steps):
            t = torch.tensor([[i * dt]]).to(state.device)
            v = self.compute_velocity(state, action, t)
            action = action + v * dt
            
        return action
```

### 5.2 ì‹¤ì œ ì‚¬ìš© ì˜ˆì‹œ

```python
# ëª¨ë¸ ì´ˆê¸°í™”
model = FlowMatchingPolicy(
    state_dim=512,  # Vision features
    action_dim=7,   # 7-DoF robot
    hidden_dim=256
)

# í›ˆë ¨
optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)

for epoch in range(epochs):
    for batch in dataloader:
        state = batch['state']
        action_expert = batch['action']  # Expert demonstration
        action_noise = torch.randn_like(action_expert)  # Random init
        
        loss = model.training_loss(state, action_noise, action_expert)
        
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

# ì¶”ë¡  (50Hz)
with torch.no_grad():
    state = get_current_state()
    action_init = torch.zeros(1, 7)  # Start from rest
    
    action = model.generate(
        state, 
        action_init,
        num_steps=5  # 5 steps = 20ms @ 50Hz
    )
    
    execute_action(action)
```

---

## 6. ì‹¤ìŠµ ê°€ì´ë“œ

### 6.1 í™˜ê²½ ì„¤ì •

```bash
# 1. í™˜ê²½ ìƒì„±
conda create -n pi0_study python=3.9
conda activate pi0_study

# 2. í•„ìˆ˜ íŒ¨í‚¤ì§€
pip install torch torchvision
pip install transformers  # For PaliGemma
pip install scipy numpy matplotlib

# 3. ì‹œë®¬ë ˆì´ì…˜ í™˜ê²½
pip install pybullet
pip install gym
```

### 6.2 ê°„ë‹¨í•œ 2D ì‹¤ìŠµ

```python
"""
2D Navigation with Flow Matching
ëª©í‘œ: (0,0) â†’ (1,1) ì´ë™ í•™ìŠµ
"""

import numpy as np
import matplotlib.pyplot as plt

class Simple2DFlow:
    def __init__(self):
        self.velocity_fn = lambda x, t: np.array([1.0, 1.0])  # ëŒ€ê°ì„  ì´ë™
    
    def demonstrate(self):
        # Generate trajectory
        positions = []
        pos = np.array([0.0, 0.0])
        
        for t in np.linspace(0, 1, 50):
            positions.append(pos.copy())
            velocity = self.velocity_fn(pos, t)
            pos += velocity * 0.02
        
        positions = np.array(positions)
        
        # Plot
        plt.figure(figsize=(8, 8))
        plt.plot(positions[:, 0], positions[:, 1], 'b-', linewidth=2)
        plt.scatter([0], [0], c='green', s=100, label='Start')
        plt.scatter([1], [1], c='red', s=100, label='Goal')
        plt.xlabel('X')
        plt.ylabel('Y')
        plt.title('Flow Matching Trajectory')
        plt.legend()
        plt.grid(True)
        plt.axis('equal')
        plt.show()

# ì‹¤í–‰
flow = Simple2DFlow()
flow.demonstrate()
```

### 6.3 í•™ìŠµ ì²´í¬ë¦¬ìŠ¤íŠ¸

```markdown
## Week 1: ì´ë¡  ê¸°ì´ˆ
- [ ] Diffusion Models ë…¼ë¬¸ ì •ë…
- [ ] Flow Matching ë…¼ë¬¸ ì •ë…
- [ ] Optimal Transport ê¸°ì´ˆ ì´í•´

## Week 2: Ï€0 ë¶„ì„
- [ ] Ï€0 ë…¼ë¬¸ ì •ë… (3íšŒ)
- [ ] ì•„í‚¤í…ì²˜ ë„í‘œ ê·¸ë¦¬ê¸°
- [ ] ì˜ì‚¬ì½”ë“œ ì‘ì„±

## Week 3: êµ¬í˜„
- [ ] 2D toy example êµ¬í˜„
- [ ] Flow Matching í›ˆë ¨ ì½”ë“œ
- [ ] ì‹œê°í™” ë„êµ¬ ê°œë°œ

## Week 4: í™•ì¥
- [ ] 3D manipulation ì‹œë„
- [ ] PyBullet í†µí•©
- [ ] ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬
```

---

## ğŸ“š ì¶”ê°€ í•™ìŠµ ìë£Œ

### ë…¼ë¬¸
1. **Flow Matching**: https://arxiv.org/abs/2210.02747
2. **Ï€0 Blog**: https://physicalintelligence.company/blog/pi0
3. **Rectified Flow**: https://arxiv.org/abs/2209.03003

### ì½”ë“œ
1. **Flow Matching Tutorial**: https://github.com/atong01/conditional-flow-matching
2. **Diffusion Policy**: https://github.com/columbia-ai-robotics/diffusion_policy

### ê°•ì˜
1. **Optimal Transport**: https://youtu.be/6iR1E6t1MMQ
2. **Generative Models**: CS236 Stanford

---

*ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸: 2025ë…„ 1ì›”*
*ì‘ì„±ì: VLA Research Assistant*